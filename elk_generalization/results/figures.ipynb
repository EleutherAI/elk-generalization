{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import get_result_dfs\n",
    "\n",
    "models = [\n",
    "    # \"atmallen/pythia-410m\",\n",
    "    # \"atmallen/pythia-1b\",\n",
    "    # \"atmallen/pythia-1.4b\",\n",
    "    # \"atmallen/pythia-2.8b\",\n",
    "    # \"atmallen/pythia-6.9b\",\n",
    "    # \"atmallen/pythia-12b\",\n",
    "    # \"atmallen/Llama-2-7b-hf\",\n",
    "    \"atmallen/Mistral-7B-v0.1\",\n",
    "]\n",
    "model_scales = {\n",
    "    \"pythia-410m\": 0.41,\n",
    "    \"pythia-1b\": 1,\n",
    "    \"pythia-1.4b\": 1.4,\n",
    "    \"pythia-2.8b\": 2.8,\n",
    "    \"pythia-6.9b\": 6.9,\n",
    "    \"pythia-12b\": 12,\n",
    "    \"Llama-2-7b-hf\": 7,\n",
    "    \"Mistral-7B-v0.1\": 7,\n",
    "}\n",
    "method_titles = {\n",
    "    \"lr\": \"LogR\",\n",
    "    \"mean-diff\": \"Diff-in-means\",\n",
    "    \"lda\": \"LDA\",\n",
    "    \"lr-on-pair\": \"LogR on contrast pair\",\n",
    "    \"ccs\": \"CCS\",\n",
    "    \"crc\": \"CRC\",\n",
    "}\n",
    "\n",
    "ds_names = [\n",
    "    # \"capitals\",\n",
    "    # \"hemisphere\",\n",
    "    # \"population\",\n",
    "    # \"sciq\",\n",
    "    # \"sentiment\",\n",
    "    # \"nli\",\n",
    "    # \"authors\",\n",
    "    # \"bookrating\",\n",
    "    \"addition_increment0\",\n",
    "    \"subtraction_increment0\",\n",
    "    \"multiplication_increment0\",\n",
    "    \"modularaddition_increment0\",\n",
    "    \"squaring_increment0\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr, to = \"A\", \"A\"\n",
    "filter_by = \"disagree\"\n",
    "metric = \"auroc\"\n",
    "methods = [\"mean-diff\", \"lr\"]\n",
    "#     \"lr\", \"mean-diff\", \"lda\",\n",
    "#     \"lr-on-pair\", \"ccs\", \"crc\",\n",
    "# ]\n",
    "root = \"../../experiments/\"\n",
    "rs = dict()\n",
    "for reporter in methods:\n",
    "    avg_reporter_results, result_dfs, avg_lm_result, lm_results = get_result_dfs(models, fr, to, ds_names, label_col=\"alice_label\", filter_by=filter_by, metric=metric, reporter=reporter, root_dir=root)\n",
    "    rs[reporter] = (avg_reporter_results, result_dfs, avg_lm_result, lm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, sharey=True, sharex=True, figsize=(11, 5), dpi=200)\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    avg_reporter_results, results_dfs, avg_lm_result, lm_results = rs[method]\n",
    "    for key, result_df, lm_result in zip(results_dfs.keys(), results_dfs.values(), lm_results.values()):\n",
    "        ax.plot(result_df[\"layer_frac\"], result_df[metric], alpha=0.2, color=\"fuchsia\", linewidth=0.5, label=key)\n",
    "\n",
    "    ax.plot(avg_reporter_results[\"layer_frac\"], avg_reporter_results[metric], label=\"probe output\", linewidth=2, color=\"fuchsia\")\n",
    "\n",
    "    ax.hlines(avg_lm_result, 0, 1, label=\"final layer LM output\", color=\"dodgerblue\", linewidth=2, linestyle=\"-\")\n",
    "    ax.hlines(0.5, 0, 1, label=\"random\", color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "    if i % 3 == 0:\n",
    "        lab = {\n",
    "            \"disagree\": f\"{metric.upper()}\" + \" on $\\\\bf{disagreements}$\",\n",
    "            \"agree\": f\"{metric.upper()}\" + \" on $\\\\bf{agreements}$\",\n",
    "            \"all\": f\"{metric.upper()}\" + \" on $\\\\bf{all\\\\ examples}$\",\n",
    "        }[filter_by]\n",
    "        ax.set_ylabel(lab, fontsize=12)\n",
    "    \n",
    "    if i >= 3:\n",
    "        ax.set_xlabel(\"Layer (fraction of max)\", fontsize=12)\n",
    "    \n",
    "    ax.set_title(method_titles[method], fontsize=13)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(-0.01, 1.01)\n",
    "    if i == 3:\n",
    "        ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"../../figures\", exist_ok=True)\n",
    "plt.savefig(f\"../../figures/layerwise_auroc_qualitative_{fr}_{to}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr, to = \"AE\", \"BH\"\n",
    "filter_by = \"disagree\"\n",
    "metric = \"auroc\"\n",
    "method = \"lr\"\n",
    "root = \"../../experiments/\"\n",
    "avg_reporter_results, result_dfs, avg_lm_result, lm_results = get_result_dfs(models, templates, fr, to, label_col=\"alice_label\", filter_by=filter_by, metric=metric, reporter=method, root_dir=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "plt.figure(figsize=(4.3, 2.6), dpi=300)\n",
    "\n",
    "ax = plt.gca()\n",
    "for key, result_df, lm_result in zip(result_dfs.keys(), result_dfs.values(), lm_results.values()):\n",
    "    ax.plot(result_df[\"layer_frac\"], result_df[metric], alpha=0.2, color=\"fuchsia\", linewidth=0.5)\n",
    "    \n",
    "ax.plot(avg_reporter_results[\"layer_frac\"], avg_reporter_results[metric], label=\"probe output (avg over LMs)\", linewidth=2, color=\"fuchsia\")\n",
    "\n",
    "ax.hlines(avg_lm_result, 0, 1, label=\"final layer LM output (avg)\", color=\"dodgerblue\", linewidth=2, linestyle=\"-\")\n",
    "ax.hlines(0.5, 0, 1, label=\"random\", color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "\n",
    "lab = {\n",
    "    \"disagree\": \"Truthfulness\\n$^{{(AUROC\\\\ on\\\\ disagreements)}}$\",\n",
    "    \"agree\": f\"{metric.upper()}\" + \" on $\\\\bf{agreements}$\",\n",
    "    \"all\": f\"{metric.upper()}\" + \" on $\\\\bf{all\\\\ examples}$\",\n",
    "}[filter_by]\n",
    "ax.set_ylabel(lab, fontsize=12)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Layer (fraction of max)\", fontsize=12)\n",
    "\n",
    "ax.set_title(method_titles[method], fontsize=13)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-0.01, 1.01)\n",
    "ax.legend(loc=[0.01, 0.07])\n",
    "\n",
    "os.makedirs(\"../../figures\", exist_ok=True)\n",
    "plt.savefig(f\"../../figures/twitter_{fr}_{to}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from viz import interpolate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set color palette\n",
    "palette = sns.color_palette(\"tab20\", 20)\n",
    "sns.set_palette(palette)\n",
    "fr, to = \"AE\", \"AE\"\n",
    "against_col = \"alice_labels\"\n",
    "root = Path(\"../../experiments\")\n",
    "plt.figure(figsize=(5, 3), dpi=100)\n",
    "cmap = plt.get_cmap('coolwarm')\n",
    "\n",
    "for q_idx in [30, 20, 17, 16, 15, 14, 13, 10, 0,]:\n",
    "    layers_dict = dict()\n",
    "    aurocs_dict = dict()\n",
    "    for model in models:\n",
    "        for template in templates:\n",
    "            model_last = model.split(\"/\")[-1]\n",
    "            results = torch.load(root / f\"{model_last}-{template}\" / to / \"test\" / f\"{fr}_random_aucs_against_{against_col}.pt\", map_location=\"cpu\")\n",
    "            aurocs = [list(results[i][\"quantiles\"].values())[q_idx] for i in range(len(results))]\n",
    "            \n",
    "            layers_dict[(model, template)] = np.arange(len(results))\n",
    "            aurocs_dict[(model, template)] = aurocs\n",
    "\n",
    "    layer_fracs, avg_aurocs = interpolate(list(layers_dict.values()), list(aurocs_dict.values()), 501)\n",
    "\n",
    "    q = list(results[0][\"quantiles\"].keys())[q_idx]\n",
    "    lab = \"$2^{\" + str(int(np.log2(q))) + \"}$\" if q <= 0.5 else \"$1-2^{\" + str(int(np.log2(1 - q))) + \"}$\"\n",
    "    plt.plot(layer_fracs, avg_aurocs, label=lab, linewidth=2, color=cmap(q))\n",
    "\n",
    "plt.legend(loc=[1.04, -0.1], title=\"quantile\", fontsize=11)\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Layer (fraction of max)\", fontsize=13)\n",
    "plt.ylabel(\"AUROC on\\nall examples\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.title(f\"{fr}$\\\\to${to} random baseline\", fontsize=13)\n",
    "plt.savefig(f\"../../figures/layerwise_auroc_random_{fr}_{to}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All transfer experiments for the appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [(\"A\", \"A\", \"disagree\"), (\"A\", \"B\", \"disagree\"), (\"B\", \"B\", \"disagree\"), (\"B\", \"A\", \"disagree\"), \n",
    "        (\"A\", \"AH\", \"all\"), (\"AE\", \"AH\", \"all\"), (\"A\", \"BH\", \"all\"), (\"AE\", \"BH\", \"all\")]\n",
    "metric = \"auroc\"\n",
    "reporter = \"crc\"\n",
    "root = \"../../experiments/\"\n",
    "rs = dict()\n",
    "for i, (fr, to, filter_by) in enumerate(exps):\n",
    "    avg_reporter_results, result_dfs, avg_lm_result, lm_results = get_result_dfs(models, templates, fr, to, label_col=\"alice_label\", filter_by=filter_by, metric=metric, reporter=reporter, root_dir=root)\n",
    "    rs[(fr, to)] = (avg_reporter_results, result_dfs, avg_lm_result, lm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# get viridis colors in a list (not css4)\n",
    "cmap = lambda x: plt.get_cmap('winter')( (np.log(x) - np.log(0.41)) / (np.log(12) - np.log(0.41)) )\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, sharex=True, sharey=True, figsize=(10, 7), dpi=200)\n",
    "\n",
    "for i, (fr, to, filter_by) in enumerate(exps):\n",
    "    ax = axes[i // 2][i % 2]\n",
    "    avg_reporter_results, results_dfs, avg_lm_result, lm_results = rs[(fr, to)]\n",
    "    for key, result_df, lm_result in zip(results_dfs.keys(), results_dfs.values(), lm_results.values()):\n",
    "        ax.plot(result_df[\"layer_frac\"], result_df[metric], alpha=0.4, color=cmap(model_scales[key[0].split(\"/\")[-1]]), linewidth=0.5)\n",
    "        \n",
    "    ax.plot(avg_reporter_results[\"layer_frac\"], avg_reporter_results[metric], label=\"LR probe\", linewidth=2, color=\"fuchsia\")\n",
    "\n",
    "    ax.hlines(avg_lm_result, 0, 1, label=\"Final layer LM output\", color=\"dodgerblue\", linewidth=2, linestyle=\"-\")\n",
    "    ax.hlines(0.5, 0, 1, label=\"random\", color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        lab = {\n",
    "            \"disagree\": f\"{metric.upper()}\" + \" on\\n$\\\\bf{disagreements}$\",\n",
    "            \"agree\": f\"{metric.upper()}\" + \" on\\n$\\\\bf{agreements}$\",\n",
    "            \"all\": f\"{metric.upper()}\" + \" on\\n$\\\\bf{all\\\\ examples}$\",\n",
    "        }[filter_by]\n",
    "        ax.set_ylabel(lab, fontsize=11.5)\n",
    "    if i >= 6:\n",
    "        ax.set_xlabel(\"Layer (fraction of max)\", fontsize=12)\n",
    "    if fr == to:\n",
    "        title = fr.title() + \" (no transfer)\"\n",
    "    else:\n",
    "        title = (f\"{fr} → {to}\")\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(-0.01, 1.01)\n",
    "    if i == 0:\n",
    "        ax.legend(loc=\"lower right\")\n",
    "\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.25))\n",
    "plt.suptitle(method_titles[reporter], fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# # make a vertical colorbar\n",
    "import matplotlib as mpl\n",
    "norm = mpl.colors.Normalize(vmin=np.log(0.41), vmax=np.log(12))\n",
    "sm = plt.cm.ScalarMappable(cmap=\"winter\", norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=axes.ravel().tolist(), orientation=\"vertical\", pad=0.1, aspect=40)\n",
    "cbar.ax.set_ylabel(\"Model size (B parameters)\", fontsize=12)\n",
    "cbar.ax.yaxis.set_label_position(\"left\")\n",
    "cbar.ax.yaxis.set_ticks_position(\"left\")\n",
    "cbar.ax.tick_params(axis=\"y\", labelsize=12, rotation=0)\n",
    "cbar.set_ticks(np.log(np.array([0.41, 1, 2.8, 7, 12])))\n",
    "cbar.ax.set_yticklabels([\"0.41\", \"1\", \"2.8\", \"7\", \"12\"])\n",
    "\n",
    "\n",
    "os.makedirs(\"../../figures\", exist_ok=True)\n",
    "plt.savefig(f\"../../figures/layerwise_auroc_{reporter}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot for ID and OOD performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "contrast_pairs = False\n",
    "exps = {\n",
    "    \"lr-on-pair\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "    \"ccs\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "    \"crc\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "} if contrast_pairs else {\n",
    "    \"lr\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "    \"mean-diff\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "    \"lda\": [(\"AE\", \"AE\"), (\"AE\", \"BH\")],\n",
    "}\n",
    "id_aurocs = defaultdict(list)\n",
    "ood_aurocs = defaultdict(list)\n",
    "for method in exps:\n",
    "    for i, (fr, to) in enumerate(exps[method]):\n",
    "        try:\n",
    "            avg_reporter_results, result_dfs, avg_lm_result, lm_results = get_result_dfs(models, templates, fr, to, filter_by=\"all\", label_col=\"alice_label\", reporter=method)\n",
    "            for model in models:\n",
    "                for template in templates:\n",
    "                    aucs = result_dfs[(model, template)][\"auroc\"].values\n",
    "                    if to == \"AE\" and fr == \"AE\":\n",
    "                        id_aurocs[method].extend(aucs)\n",
    "                    elif to == \"BH\" and fr == \"AE\":\n",
    "                        ood_aurocs[method].extend(aucs)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unexpected experiment\")\n",
    "\n",
    "        except KeyError:\n",
    "            print(f\"Experiment {fr} → {to} not found for method {method} with model {model} and template {template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "colors = sns.color_palette(\"Set2\")\n",
    "\n",
    "plt.figure(figsize=(4, 4), dpi=150)\n",
    "for i, method in enumerate(id_aurocs):\n",
    "    for j in range(len(id_aurocs[method])):\n",
    "        plt.scatter(id_aurocs[method][j], ood_aurocs[method][j], label=method_titles[method] if j == 0 else None, alpha=0.5, s=5, zorder=np.random.randint(0, 6), c=colors[i])\n",
    "plt.plot([0, 2], [0, 2], color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.axhline(0.5, color=\"grey\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.xlim(0.35, 1.02)\n",
    "plt.ylim(-0.02, 1.02)\n",
    "plt.xlabel(\"AUROC on AE (no transfer)\", fontsize=13)\n",
    "plt.ylabel(\"Transfer AUROC for AE$\\\\to$BH\", fontsize=13)\n",
    "os.makedirs(\"../../figures\", exist_ok=True)\n",
    "plt.legend(fontsize=12, loc=\"lower left\")\n",
    "title = \"Probing on contrast pair\" if contrast_pairs else \"Probing on final prompt token\"\n",
    "plt.title(title, fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../../figures/transfer_scatter_{'_'.join(exps.keys())}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All transfer results at middle layer bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from viz import first_good_layer_idx\n",
    "import os\n",
    "\n",
    "\n",
    "transfers_all = [\n",
    "        ((\"A\", \"A\"), (\"A\", \"B\")),\n",
    "        ((\"B\", \"B\"), (\"B\", \"A\")),\n",
    "        ((\"A\", \"AH\"), (\"AE\", \"AH\")),\n",
    "        ((\"A\", \"BH\"), (\"AE\", \"BH\")),\n",
    "]\n",
    "filter_bys = [\"disagree\", \"disagree\", \"all\", \"all\"]\n",
    "methods = [\"lm\", \"lr\", \"mean-diff\", \"lda\", \"lr-on-pair\", \"ccs\", \"crc\"]\n",
    "dfs = []\n",
    "for frame, (transfers, filter_by) in enumerate(zip(transfers_all, filter_bys)):\n",
    "    try:\n",
    "        # make a df with a column for auroc on middle layer, and a column for method, and column for transfer,\n",
    "        # where each row is a model/template/method combo\n",
    "        df = []\n",
    "        for method in methods:\n",
    "            for (fr, to) in transfers:\n",
    "                if method == \"lm\":\n",
    "                    _, _, _, lm_results = get_result_dfs(models, templates, fr, to, filter_by=\"disagree\", label_col=\"alice_label\", reporter=\"lr\")\n",
    "                    for model in models:\n",
    "                        for template in templates:\n",
    "                            df.append({\n",
    "                                \"auroc\": lm_results[(model, template)],\n",
    "                                \"method\": \"Target distr\\nLM output\",\n",
    "                                \"transfer\": f\"{fr}$\\\\to${to}\",\n",
    "                            })\n",
    "                else:\n",
    "                    _, result_dfs, _, _ = get_result_dfs(models, templates, fr, to, filter_by=filter_by, label_col=\"alice_label\", reporter=method)\n",
    "                    # pick layer on source distribution with all examples, measured against source labels\n",
    "                    _, id_result_dfs, _, _ = get_result_dfs(models, templates, fr, fr, filter_by=\"all\", label_col=\"label\", reporter=method)\n",
    "                    for model in models:\n",
    "                        for template in templates:\n",
    "                            layer_idx = first_good_layer_idx(id_result_dfs[(model, template)], thresh=0.95)\n",
    "                            auroc = result_dfs[(model, template)][\"auroc\"].values[layer_idx]\n",
    "                            df.append({\n",
    "                                \"auroc\": auroc,\n",
    "                                \"method\": method_titles[method].replace(\"LogR on contrast pair\", \"LogR on\\ncontrast pair\"),\n",
    "                                \"transfer\": f\"{fr}$\\\\to${to}\",\n",
    "                            })\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Experiment not found: {e}\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, sharey=True, figsize=(10, 5), dpi=150)\n",
    "for frame, (df, filter_by) in enumerate(zip(dfs, filter_bys)):\n",
    "    ax = axes[frame // 2][frame % 2]\n",
    "    plt.sca(ax)\n",
    "    # use std errorbars\n",
    "    sns.barplot(data=df, x=\"transfer\", y=\"auroc\", hue=\"method\", legend=frame == 3, palette=\"Set2\", errorbar=None)\n",
    "    # sns.boxplot(data=df, x=\"transfer\", y=\"auroc\", hue=\"method\", showfliers=False, palette=\"Set2\", linewidth=0.1)\n",
    "    # turn off legend\n",
    "    if frame == 3:\n",
    "        ax.get_legend().remove()\n",
    "    ax.tick_params(labelsize=14)\n",
    "    \n",
    "    if filter_by == \"all\":\n",
    "        plt.ylabel(\"AUROC on\\n$\\\\bf{all\\\\ examples}$\", fontsize=14)\n",
    "    elif filter_by == \"disagree\":\n",
    "        plt.ylabel(\"AUROC on\\n$\\\\bf{disagreements}$\", fontsize=14)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected filter_by value\" + str(filter_by))\n",
    "    plt.xlabel(\"\")\n",
    "    \n",
    "    plt.axhline(0.5, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.title(\"$\\\\bf {(\" +'abcd'[frame] + \")}$\", fontsize=15)\n",
    "\n",
    "# add legend to the right, spanning the full height\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', fontsize=14, bbox_to_anchor=(1.2, 0.5))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"../../figures\", exist_ok=True)\n",
    "plt.savefig(\"../../figures/transfer_barplot.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of results for LR and CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from viz import first_good_layer_idx\n",
    "from collections import defaultdict\n",
    "\n",
    "exps = {\n",
    "    \"lr\": [(\"AE\", \"BH\")],\n",
    "    \"mean-diff\": [(\"AE\", \"BH\")],\n",
    "    \"lda\": [(\"AE\", \"BH\")],\n",
    "    \"lr-on-pair\": [(\"AE\", \"BH\")],\n",
    "    \"ccs\": [(\"AE\", \"BH\"), (\"all\", \"BH\"),],\n",
    "    \"crc\": [(\"AE\", \"BH\"), (\"all\", \"BH\"),],\n",
    "}\n",
    "table = \\\n",
    "\"\"\"\\\\begin{table}[htbp]\n",
    "    \\\\centering\n",
    "    \\\\caption{AE\\\\(\\\\to\\\\)BH transfer AUROC broken down by probing method, model, and template setup at the Earliest Informative Layer (\\\\ref{sec:selecting_a_layer}).}\n",
    "    \\\\label{tab:transfer_all}\n",
    "    \\\\begin{tabular}{lcccccccccccc}\n",
    "        \\\\toprule\n",
    "        & & \\\\multicolumn{6}{c}{Pythia} & Llama-2 & Mistral & \\\\\\\\\n",
    "        \\\\cmidrule(lr){3-8} \\\\cmidrule(lr){9-9} \\\\cmidrule(lr){10-10}\n",
    "        & Template & 410m & 1B & 1.4B & 2.8B & 6.9B & 12B & 7B & 7B & \\\\textbf{avg} \\\\\\\\\n",
    "        \\\\midrule\n",
    "\"\"\"\n",
    "summary_table = \\\n",
    "\"\"\"\\\\begin{table}[htbp]\n",
    "    \\\\centering\n",
    "    \\\\caption{AE\\\\(\\\\to\\\\)BH transfer AUROC broken down by probing method and template setup at the Earliest Informative Layer (\\\\ref{sec:selecting_a_layer}). See Table~\\\\ref{tab:transfer_all} for results broken down by model.}\n",
    "    \\\\label{tab:transfer}\n",
    "    \\\\begin{tabular}{lcccccccc}\n",
    "        \\\\toprule\n",
    "        & \\\\textit{mixture} & \\\\textit{pers. first} & \\\\textit{pers. last} & \\\\textbf{avg} \\\\\\\\\n",
    "        \\\\midrule\n",
    "\"\"\"\n",
    "template_avgs_over_experiments = defaultdict(list)\n",
    "for method in exps:\n",
    "    for i, (fr, to) in enumerate(exps[method]):\n",
    "        method_title = method_titles[method].replace(\"LogR on contrast pair\", \"\\\\begin{tabular}[c]{@{}c@{}}LogR on\\\\\\\\cont. pair\\\\end{tabular}\").replace(\"Diff of means\", \"\\\\begin{tabular}[c]{@{}c@{}}Diff of\\\\\\\\means\\\\end{tabular}\")\n",
    "        if fr == \"all\":\n",
    "            table += f\"        \\\\multirow{{4}}{{*}}{{\\\\begin{{tabular}}[c]{{@{{}}l@{{}}}}{method_title}\\\\\\\\(all\\\\(\\\\to\\\\){to})\\\\end{{tabular}}}} & \\\\textit{{mixture}} & \"\n",
    "            summary_table += f\"        {method_titles[method]} (all\\\\(\\\\to\\\\){to}) & \"\n",
    "        else:\n",
    "            table += f\"        \\\\multirow{{4}}{{*}}{{{method_title}}} & \\\\textit{{mixture}} & \"\n",
    "            summary_table += f\"        {method_titles[method]} & \"\n",
    "        _, result_dfs, _, lm_results = get_result_dfs(models, templates, fr, to, filter_by=\"all\", label_col=\"alice_label\", reporter=method)\n",
    "        \n",
    "        # we use alice's easy no transfer data to select the layer\n",
    "        _, id_result_dfs, _, _ = get_result_dfs(models, templates, \"AE\", \"AE\", filter_by=\"all\", label_col=\"alice_label\", reporter=method)\n",
    "        \n",
    "        model_avgs = defaultdict(float)\n",
    "        for j, template in enumerate(templates):\n",
    "            template_avg = 0\n",
    "            for model in models:\n",
    "                \n",
    "                layer_idx = first_good_layer_idx(id_result_dfs[(model, template)], thresh=0.95)\n",
    "\n",
    "                auc = result_dfs[(model, template)][\"auroc\"].values[layer_idx]\n",
    "                model_avgs[model] += auc\n",
    "                template_avg += auc\n",
    "                table += f\"{auc:.2f} & \"\n",
    "                                \n",
    "            template_avg /= len(models)\n",
    "            table += f\"{template_avg:.2f} \\\\\\\\ \\n\"\n",
    "            table += \"        \" + [\"& \\\\textit{{pers. first}} & \", \"& \\\\textit{{pers. last}} & \", \"& \\\\textbf{{avg}} & \"][j]\n",
    "            summary_table += f\"{template_avg:.2f} & \"\n",
    "            template_avgs_over_experiments[template].append(template_avg)\n",
    "\n",
    "        for model in models:\n",
    "            model_avgs[model] /= len(templates)\n",
    "            table += f\"{model_avgs[model]:.2f} & \"\n",
    "\n",
    "        avg_auroc = sum(model_avgs.values()) / len(models)\n",
    "        table += \"\\\\textbf{{\" + f\"{avg_auroc:.2f}\" + \"}} \\\\\\\\ \\n\"\n",
    "        table += \"        \\\\midrule\\n\"\n",
    "        summary_table += f\"{avg_auroc:.2f} \\\\\\\\ \\n\"\n",
    "\n",
    "# avg row\n",
    "summary_table += \"        \\\\midrule\\n\"\n",
    "summary_table += \"        \\\\bf{avg} & \"\n",
    "ova_avg = 0\n",
    "for template in templates:\n",
    "    avg = sum(template_avgs_over_experiments[template]) / len(template_avgs_over_experiments[template])\n",
    "    ova_avg += avg\n",
    "    summary_table += f\"{avg:.2f} & \"\n",
    "ova_avg /= len(templates)\n",
    "summary_table += f\"{ova_avg:.2f} \\\\\\\\ \\n\"\n",
    "\n",
    "# lm results\n",
    "_, _, _, lm_results = get_result_dfs(models, templates, \"AE\", \"AH\", filter_by=\"all\", label_col=\"alice_label\", reporter=\"crc\")  # any reporter will do\n",
    "table += \"        \\\\multirow{4}{*}{\\\\begin{tabular}[c]{@{}l@{}}LM\\\\\\\\on AH\\\\end{tabular}} & \\\\textit{mixture} & \"\n",
    "summary_table += \"        \\\\midrule\\n\"\n",
    "summary_table += \"        LM on AH & \"\n",
    "lm_avg = 0\n",
    "model_avgs = defaultdict(float)\n",
    "for i, template in enumerate(templates):\n",
    "    template_avg = 0\n",
    "    for model in models:\n",
    "        lm_result = lm_results[(model, template)]\n",
    "        template_avg += lm_result\n",
    "        table += f\"{lm_result:.2f} & \"\n",
    "        model_avgs[model] += lm_result\n",
    "    template_avg /= len(models)\n",
    "    table += f\"{template_avg:.2f} \\\\\\\\ \\n\"\n",
    "    table += \"        \" + [\"& \\\\textit{pers. first} & \", \"& \\\\textit{pers. last} & \", \"& \\\\textbf{avg} & \"][i]\n",
    "    summary_table += f\"{template_avg:.2f} & \"\n",
    "    lm_avg += template_avg\n",
    "lm_avg /= len(templates)\n",
    "for model in models:\n",
    "    model_avgs[model] /= len(templates)\n",
    "    table += f\"{model_avgs[model]:.2f} & \"\n",
    "table += f\"\\\\bf{lm_avg:.2f} \\\\\\\\ \\n\"\n",
    "summary_table += f\"{lm_avg:.2f} \\\\\\\\ \\n\"\n",
    "\n",
    "summary_table += \"        \\\\bottomrule\\n\"\n",
    "summary_table += \"    \\\\end{tabular}\\n\\\\end{table}\"\n",
    "table += \"        \\\\bottomrule\\n\"\n",
    "table += \"    \\\\end{tabular}\\n\\\\end{table}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the results from anomaly experiments and put them in a tex table\n",
    "import os\n",
    "import json\n",
    "\n",
    "subtract_diag = False\n",
    "root = \"../../anomaly-results/\"\n",
    "caption = \"Mechanistic anomaly detection AUROC\"\n",
    "if subtract_diag:\n",
    "    caption += \" using diagonal subtraction\"\n",
    "table = \\\n",
    "\"\"\"\\\\begin{table}[b!]\n",
    "    \\\\centering\n",
    "    \\\\caption{\"\"\" + caption + \"\"\"}\n",
    "    \\\\label{tab:anomaly_detection}\n",
    "    \\\\begin{tabular}{lccccccccccc}\n",
    "        \\\\toprule\n",
    "        & \\\\multicolumn{6}{c}{Pythia} & Llama-2 & Mistral & \\\\\\\\\n",
    "        \\\\cmidrule(lr){2-7} \\\\cmidrule(lr){8-8} \\\\cmidrule(lr){9-9}\n",
    "         & 410m & 1B & 1.4B & 2.8B & 6.9B & 12B & 7B & 7B & \\\\textbf{avg} \\\\\\\\\n",
    "        \\\\midrule\n",
    "\"\"\"\n",
    "for method in [\"lr\", \"mean-diff\", \"lda\", \"lr-on-pair\", \"ccs\", \"crc\"]:\n",
    "    table += f\"        {method_titles[method]} & \"\n",
    "    overall_avg = 0\n",
    "    for model in models:\n",
    "        avg = 0\n",
    "        for template in templates:\n",
    "            model_last = model.split(\"/\")[-1]\n",
    "            name = f\"mahalanobis_{model_last}-{template}_{method}\"\n",
    "            if subtract_diag:\n",
    "                name += \"_subtract_diag\"\n",
    "            with open(os.path.join(root, name + \".json\")) as f:\n",
    "                auroc = json.load(f)[\"auroc\"]\n",
    "            avg += auroc\n",
    "        avg /= len(templates)\n",
    "        table += f\"{avg:.3f} & \"\n",
    "        overall_avg += avg\n",
    "    overall_avg /= len(models)\n",
    "    table += \"\\\\textbf{\" + f\"{overall_avg:.3f}\" + \"} \\\\\\\\ \\n\"\n",
    "table += \"        \\\\bottomrule\\n\"\n",
    "table += \"    \\\\end{tabular}\\n\\\\end{table}\"\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results showing that Alice's and Bob's representations are not negations of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute agreement rate for A -> B with B -> B, and A -> A with B -> A\n",
    "# describe it as agreement rate of alice and bob's representations on examples where Alice and Bob agree, \n",
    "# when Alice is in the context and when Bob is in the context\n",
    "from viz import get_agreement_rate\n",
    "\n",
    "for reporter in (\"lr\", \"ccs\", \"crc\", \"mean-diff\", \"lr-on-pair\", \"lda\"):\n",
    "    ag_rates = list(get_agreement_rate(models, templates, target_distr, 'A', 'B', reporter) for target_distr in (\"A\", \"B\"))\n",
    "    agreement_rate = sum(ag_rates) / 2\n",
    "    print(f\"Reporter: {reporter}\")\n",
    "    print(f\"Agreement rate: {agreement_rate}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How hard is hard and easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distr in [\"AE\", \"AH\"]:\n",
    "    _, _, avg_lm_result, _ = get_result_dfs(models, templates, \"AE\", distr, filter_by=\"all\", label_col=\"alice_label\", reporter=\"lr-on-pair\")\n",
    "    print(f\"LM AUROC on {distr}: {avg_lm_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "root = Path(\"../../naturalness-results/\")\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    for template in templates:\n",
    "        model_last = model.split(\"/\")[-1]\n",
    "        with open(root / f\"{model_last}-{template}.json\") as f:\n",
    "            result = json.load(f)\n",
    "        result[\"model\"] = model_last\n",
    "        result[\"template\"] = template\n",
    "        results.append(result)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss increased by an avergage of {df.loss_increase.mean():.3f}% ({df.loss_increase.quantile(0.05):.3f}, {df.loss_increase.quantile(0.95):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for s in np.random.choice(df.generation.values, 3):\n",
    "    print(s)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
