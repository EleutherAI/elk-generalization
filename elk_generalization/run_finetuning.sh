python finetuning.py --model EleutherAI/pythia-410m --save-dir ../custom-models --pile-path ../data/pile.jsonl --verbose --max-len 40 --max-pretrain-len 128 --batch-size 16 --kl-weight 0.1 --eval-every 200 --save-every 100 --epochs 100 --n-val 400 --lora-rank 2  --template "mixture" --devices 0 1 --n-train 400000
# python finetuning.py --model EleutherAI/pythia-410m --snapshot-path ../custom-models/pythia-410m/snapshot.pt  --best-checkpoint-path ../custom-models/pythia-410m/best.pt --pile-path ../data/pile.jsonl --verbose --max-len 32 --max-pretrain-len 128 --batch-size 8 --kl-weight 0.1 --eval-every 200 --save-every 100 --epochs 100 --n-val 100 --lora-rank 2 --n-train 400000
# torchrun --standalone --nproc_per_node=2 finetuning.py --model EleutherAI/pythia-160m --snapshot-path ../custom-models/pythia-160m/snapshot.pt  --best-checkpoint-path ../custom-models/pythia-160m/best.pt --pile-path ../data/pile.jsonl --verbose --max-len 32 --max-pretrain-len 128 --batch-size 8 --kl-weight 0.3 --save-every 100 --eval-every 500 --n-train 400000 --n-val 500 --epochs 10